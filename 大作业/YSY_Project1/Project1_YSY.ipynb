{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 3 (50 pt).\n",
    "Find ways to solve this SOCP optimization problem. Then use the solution w∗, b∗from this  optimization to form aclassifier.\n",
    "\n",
    "USE cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) May 21 07:24:57 PM: Encountered unexpected exception importing solver OSQP:\n",
      "ImportError('DLL load failed while importing qdldl: 找不到指定的模块。')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#封装MPM类\n",
    "class MPM():\n",
    "    def __init__(self) -> None:\n",
    "        pass\n",
    "    def optimize(self):\n",
    "        #分两类\n",
    "        x_p = self.X[self.y == 1]\n",
    "        x_n = self.X[self.y == 0]\n",
    "        #分别计算协方差矩阵\n",
    "        cov_p = np.cov(x_p.T)\n",
    "        cov_n = np.cov(x_n.T)\n",
    "        #均值\n",
    "        mu_p = np.mean(x_p,axis=0)\n",
    "        mu_n = np.mean(x_n,axis=0)\n",
    "        dim = mu_n.shape[0]\n",
    "        #1/2的协方差矩阵\n",
    "        Q_p = np.linalg.cholesky(cov_p)\n",
    "        Q_n = np.linalg.cholesky(cov_n)\n",
    "        #开始优化\n",
    "        #定义优化的变量\n",
    "        w = cp.Variable(dim)\n",
    "        equa = cp.norm(Q_n.T@w,2)+cp.norm(Q_p.T@w,2)\n",
    "        prob = cp.Problem(cp.Minimize(equa),[(mu_p-mu_n).T @ w ==1])\n",
    "        prob.solve()\n",
    "        #最优解\n",
    "        w_opt = w.value\n",
    "        k_opt = 1 / (np.sqrt(w_opt.T @ cov_p @ w_opt) + np.sqrt(w_opt.T @ cov_n @ w_opt))\n",
    "        b_opt = w_opt@mu_p - k_opt*np.sqrt(w_opt.T @ cov_n @ w_opt)\n",
    "        #计算好最优后定义此分类器参数\n",
    "        self.w = w_opt\n",
    "        self.b = b_opt\n",
    "        self.e = 1 / (k_opt**2 + 1)\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.optimize()\n",
    "    #根据得到的分类器来预测\n",
    "    def predict(self,X):\n",
    "        y = (self.w) @ (X.T) - self.b\n",
    "        y[y >= 0] = 1\n",
    "        y[y < 0] = 0\n",
    "        return y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare its performance with the original LDA, Logistic Regression, and SVM on the datasets\n",
    "we provide (including breastcancer, pima, sonar). Each time you should randomly partition it\n",
    "into 90% training set and 10% test set, and repeat that procedure 10 times to get the average\n",
    "test accuracy. Also report the average MPM’s guaranteed error e in line (1). You should achieve\n",
    "comparable results as in paper[1]."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先读取数据"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）breastcancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_question(df):# 直接删掉含有？的行\n",
    "    for col in df.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            df = df.dropna(subset=[col],axis=0)\n",
    "    return df\n",
    "def read_breastcancer(path ='./data/breast-cancer-wisconsin.txt' ):\n",
    "    data_breastcancer = pd.read_csv(path,sep='\\t',header=None)\n",
    "    # 直接删掉含有？的行\n",
    "    data_breastcancer = del_question(data_breastcancer)\n",
    "    benigndata = data_breastcancer[data_breastcancer[10]==0].values\n",
    "    maligndata = data_breastcancer[data_breastcancer[10]==1].values\n",
    "    # print(benigndata)\n",
    "    fulldata = np.append(benigndata,maligndata,axis=0)\n",
    "    # print(fulldata.shape)\n",
    "    X = fulldata[:,1:10]\n",
    "    y = fulldata[:,10]\n",
    "    return X,y\n",
    "# X,y = read_breastcancer()\n",
    "# X.shape\n",
    "# y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_diabetes(path = './data/diabetes.csv'):\n",
    "    data_diabetes = pd.read_csv(path)\n",
    "    # display(data_diabetes)\n",
    "    class1 = data_diabetes[data_diabetes['Outcome']==1].values\n",
    "    class2 = data_diabetes[data_diabetes['Outcome']==0].values\n",
    "    fulldata = np.append(class1,class2,axis=0)\n",
    "    X = fulldata[:,0:8]\n",
    "    y = fulldata[:,8]\n",
    "    return X,y\n",
    "# X, y=read_diabetes()\n",
    "# y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) sonar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sonar(path = './data/sonar_csv.csv'):\n",
    "    data_sonar = pd.read_csv(path)\n",
    "    data_sonar['Class'] = data_sonar['Class'].replace({'Rock':1,'Mine':0})\n",
    "    data_sonar=data_sonar.values\n",
    "    X = data_sonar[:,0:60]\n",
    "    y = data_sonar[:,60]\n",
    "    return X,y\n",
    "# X,y = read_sonar()\n",
    "# X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(X, y, model_MPM:MPM, model_LDA:LinearDiscriminantAnalysis, model_LR:LogisticRegression, model_SVM:SVC, name:str):\n",
    "    MPM_err = 0\n",
    "    MPM_acc = 0\n",
    "    LDA_acc = 0\n",
    "    LR_acc = 0\n",
    "    SVM_acc = 0\n",
    "    MPM_t = 0\n",
    "    LDA_t = 0\n",
    "    LR_t = 0\n",
    "    SVM_t = 0\n",
    "    for i in range(0, 10):\n",
    "        X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.1,random_state = i + 1,shuffle = True)\n",
    "\n",
    "        t1 = time()\n",
    "        model_MPM.fit(X_train, y_train)\n",
    "        t2 = time()\n",
    "        model_LDA.fit(X_train, y_train)\n",
    "        t3 = time()\n",
    "        model_LR.fit(X_train, y_train)\n",
    "        t4 = time()\n",
    "        model_SVM.fit(X_train, y_train)\n",
    "        t5 = time()\n",
    "\n",
    "        y_MPM = model_MPM.predict(X_test)\n",
    "        y_LDA = model_LDA.predict(X_test)\n",
    "        y_LR = model_LR.predict(X_test)\n",
    "        y_SVM = model_SVM.predict(X_test)\n",
    "\n",
    "        MPM_acc += np.sum(y_MPM == y_test) / y_test.shape[0]\n",
    "        LDA_acc += np.sum(y_LDA == y_test) / y_test.shape[0]\n",
    "        LR_acc += np.sum(y_LR == y_test) / y_test.shape[0]\n",
    "        SVM_acc += np.sum(y_SVM == y_test) / y_test.shape[0]\n",
    "\n",
    "        MPM_t = MPM_t + (t2 - t1)\n",
    "        LDA_t = LDA_t + (t3 - t2)\n",
    "        LR_t = LR_t + (t4 - t3)\n",
    "        SVM_t = SVM_t + (t5 - t4)\n",
    "\n",
    "        MPM_err += model_MPM.e\n",
    "    MPM_acc /= 10\n",
    "    MPM_err /= 10\n",
    "    LDA_acc /= 10\n",
    "    LR_acc /= 10\n",
    "    SVM_acc /= 10\n",
    "    MPM_t /= 10\n",
    "    LDA_t /= 10\n",
    "    LR_t /= 10\n",
    "    SVM_t /= 10\n",
    "    print(name)\n",
    "    print('LDA———— Accuracy: ', LDA_acc, 'Time: ', LDA_t)\n",
    "    print('LGS———— Accuracy: ', LR_acc, 'Time: ', LR_t)\n",
    "    print('SVM———— Accuracy: ', SVM_acc, 'Time: ', SVM_t)\n",
    "    print('MPM————Accuracy: ', MPM_acc, 'Time: ', MPM_t)\n",
    "    print('MPM guaranteed error: ', MPM_err)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "breastcancer\n",
      "LDA———— Accuracy:  0.9594202898550724 Time:  0.002652406692504883\n",
      "LGS———— Accuracy:  0.9681159420289855 Time:  0.012859487533569336\n",
      "SVM———— Accuracy:  0.9637681159420289 Time:  0.006972265243530273\n",
      "MPM————Accuracy:  0.9405797101449276 Time:  0.013753199577331543\n",
      "MPM guaranteed error:  0.15526610718499848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\prml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\envs\\prml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\envs\\prml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\envs\\prml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\envs\\prml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\envs\\prml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\envs\\prml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\envs\\prml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\envs\\prml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Anaconda\\envs\\prml\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes\n",
      "LDA———— Accuracy:  0.7740259740259742 Time:  0.002436065673828125\n",
      "LGS———— Accuracy:  0.7636363636363637 Time:  0.02573072910308838\n",
      "SVM———— Accuracy:  0.7753246753246754 Time:  0.026667189598083497\n",
      "MPM————Accuracy:  0.7597402597402598 Time:  0.01182544231414795\n",
      "MPM guaranteed error:  0.677132391654075\n",
      "sonar\n",
      "LDA———— Accuracy:  0.738095238095238 Time:  0.004142093658447266\n",
      "LGS———— Accuracy:  0.7571428571428571 Time:  0.00808563232421875\n",
      "SVM———— Accuracy:  0.7952380952380953 Time:  0.003951764106750489\n",
      "MPM————Accuracy:  0.7428571428571428 Time:  0.019269919395446776\n",
      "MPM guaranteed error:  0.3536017233036554\n"
     ]
    }
   ],
   "source": [
    "X_breastcancer,y_breastcancer= read_breastcancer()\n",
    "X_diabetes,y_diabetes= read_diabetes()\n",
    "X_sonar,y_sonar = read_sonar()\n",
    "model_MPM =MPM()\n",
    "model_LDA = LinearDiscriminantAnalysis()\n",
    "model_LR = LogisticRegression()\n",
    "model_SVM = SVC()\n",
    "train(X_breastcancer,y_breastcancer,model_MPM,model_LDA,model_LR,model_SVM,'breastcancer')\n",
    "train(X_diabetes,y_diabetes,model_MPM,model_LDA,model_LR,model_SVM,'diabetes')\n",
    "train(X_sonar,y_sonar,model_MPM,model_LDA,model_LR,model_SVM,'sonar')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

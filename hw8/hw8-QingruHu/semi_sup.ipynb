{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml, load_digits, load_iris\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics.pairwise import rbf_kernel, polynomial_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLS:\n",
    "    def __init__(self, gamma=1.0, kernel_type='poly', kernel_param=3.):\n",
    "        self.gamma = gamma\n",
    "        if kernel_type == 'poly':\n",
    "            self.kernel = polynomial_kernel\n",
    "        elif kernel_type == 'rbf':\n",
    "            self.kernel = rbf_kernel\n",
    "        self.kernel_param = kernel_param\n",
    "\n",
    "    def fit(self, X_l, Y_l):\n",
    "        self.X = X_l\n",
    "        K = self.kernel(self.X, self.X, self.kernel_param)\n",
    "        self.W = np.linalg.solve(K + self.gamma * len(X_l) * np.identity(len(X_l)), Y_l)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        K1 = self.kernel(X, self.X, self.kernel_param)\n",
    "        return K1 @ self.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LapRLS:\n",
    "    def __init__(self, gamma_A=1.0, gamma_I=1.0, n_neighbors=2, kernel_type='poly', kernel_param=3., graph_weights=9.4):\n",
    "        self.gamma_A = gamma_A\n",
    "        self.gamma_I = gamma_I\n",
    "        self.n_neighbors = n_neighbors\n",
    "        if kernel_type == 'poly':\n",
    "            self.kernel = polynomial_kernel\n",
    "        elif kernel_type == 'rbf':\n",
    "            self.kernel = rbf_kernel\n",
    "        self.kernel_param = kernel_param\n",
    "        self.graph_weights = graph_weights\n",
    "\n",
    "    def fit(self, X_l, X_u, Y_l):\n",
    "        # define Y\n",
    "        l = len(X_l)\n",
    "        u = len(X_u)\n",
    "        X = np.concatenate([X_l, X_u])\n",
    "        self.X = X\n",
    "        Y_u = np.zeros([u, Y_l.shape[1]])\n",
    "        Y = np.concatenate([Y_l, Y_u])\n",
    "\n",
    "        # 计算K近邻图\n",
    "        W = kneighbors_graph(X, self.n_neighbors, mode='distance')\n",
    "        W = np.exp(-W.todense() ** 2 / 4 * self.graph_weights)\n",
    "        W = (W + W.T) / 2\n",
    "\n",
    "        # 计算Laplacian矩阵\n",
    "        D = np.diag(W.sum(axis=1))\n",
    "        L = D - W\n",
    "\n",
    "        J = np.diag(np.concatenate([np.ones(l), np.zeros(u)]))\n",
    "        K = self.kernel(X, X, self.kernel_param)\n",
    "        self.W = np.linalg.inv(J.dot(K) + self.gamma_A*l*np.identity(l+u) + (self.gamma_I*l)/(u+l)**2*L.dot(K)).dot(Y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        K1 = self.kernel(X, self.X, self.kernel_param)\n",
    "        return K1 @ self.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(name='digits'):\n",
    "    if name == 'digits':\n",
    "        dset = load_digits()\n",
    "    elif name == 'usps':\n",
    "        dset = fetch_openml('usps', version=1)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid dataset name\")\n",
    "\n",
    "    X = dset.data\n",
    "    y = dset.target\n",
    "    if not isinstance(y[0], int):\n",
    "        y = y.astype(int)\n",
    "    y = y - np.min(y)\n",
    "    return X, y\n",
    "\n",
    "def highlight_wrong_points(ax, X_t, y, y_pred, title):\n",
    "    correct = y == y_pred\n",
    "    incorrect = np.logical_not(correct)\n",
    "\n",
    "    cmap = plt.cm.Set1\n",
    "    norm = plt.Normalize(y.min(), y.max())\n",
    "\n",
    "    ax.scatter(X_t[correct, 0], X_t[correct, 1])#, c=cmap(norm(y[correct])), edgecolor='k', marker='o')\n",
    "    ax.scatter(X_t[incorrect, 0], X_t[incorrect, 1], c=cmap(norm(y[incorrect])), edgecolor='k', marker='x')\n",
    "\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset_name):\n",
    "    # 加载数据集\n",
    "    X, y = load_dataset(dataset_name)\n",
    "\n",
    "    # 预处理\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # 划分训练、验证、测试集\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=1 / 9, random_state=42)\n",
    "\n",
    "    # 创建半监督数据集\n",
    "    n_labeled = len(X_train) // 10\n",
    "    mask = np.zeros(len(X_train), dtype=bool)\n",
    "    mask[:n_labeled] = True\n",
    "    np.random.shuffle(mask)\n",
    "\n",
    "    # 监督线性回归（仅使用带有标签的样本）\n",
    "    X_train_labeled = X_train[mask]\n",
    "    y_train_labeled = y_train[mask]\n",
    "    n_classes = len(np.unique(y))\n",
    "    y_train_one_hot = np.eye(n_classes)[y_train_labeled]\n",
    "\n",
    "    ## RLS\n",
    "    # 创建并训练模型\n",
    "    rls = RLS()\n",
    "    rls.fit(X_train_labeled, y_train_one_hot)\n",
    "\n",
    "    # 预测\n",
    "    y_pred_rls = rls.predict(X_test)\n",
    "    y_pred_rls = np.argmax(y_pred_rls, axis=1).squeeze()\n",
    "\n",
    "    # 计算准确率\n",
    "    accuracy_RLS = np.mean(y_pred_rls == y_test)\n",
    "    print(\"RLS Accuracy:\", accuracy_RLS)\n",
    "\n",
    "    ## LapRLS\n",
    "    # 使用验证集选择最佳的gamma_I\n",
    "    best_gamma_I = 0\n",
    "    best_accuracy = 0\n",
    "    for gamma_I in np.logspace(1, 6, 6):\n",
    "        laprls = LapRLS(gamma_I=gamma_I)\n",
    "        laprls.fit(X_train[mask], X_train[~mask], y_train_one_hot)\n",
    "\n",
    "        y_pred_val = laprls.predict(X_val)\n",
    "        y_pred_val = np.argmax(y_pred_val, axis=1)\n",
    "        # fix the bug\n",
    "        y = []\n",
    "        for i in y_pred_val:\n",
    "            y.append(i.item())\n",
    "        y_pred_val = np.array(y)\n",
    "        accuracy = np.mean(y_pred_val == y_val)\n",
    "        # print(gamma_I, accuracy)\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_gamma_I = gamma_I\n",
    "\n",
    "    # 使用最佳的gamma_I重新训练模型\n",
    "    laprls = LapRLS(gamma_I=best_gamma_I)\n",
    "    laprls.fit(X_train[mask], X_train[~mask], y_train_one_hot)\n",
    "\n",
    "    # 预测\n",
    "    y_pred_laprls = laprls.predict(X_test)\n",
    "    y_pred_laprls = np.argmax(y_pred_laprls, axis=1)\n",
    "    # fix the bug\n",
    "    y = []\n",
    "    for i in y_pred_laprls:\n",
    "        y.append(i.item())\n",
    "    y_pred_laprls = np.array(y)\n",
    "\n",
    "    # 计算准确率\n",
    "    accuracy_manifold = np.mean(y_pred_laprls == y_test)\n",
    "    print(f\"LapRLS Accuracy (best gamma_I = {best_gamma_I}):\", accuracy_manifold)\n",
    "\n",
    "    # methods = {\n",
    "    #     # TODO: 调用sklearn中合适的降维方法，下面给出了PCA的例子\n",
    "    #     'PCA': PCA(n_components=2),\n",
    "    #     # 'LDA':\n",
    "    #     # 'MDS':\n",
    "    #     # 'Isomap':\n",
    "    #     # 'LLE':\n",
    "    #     # 't-SNE':\n",
    "    # }\n",
    "\n",
    "    # # 绘制降维后的可视化图\n",
    "    # for model in [\"laprls\", \"rls\"]:\n",
    "    #     fig, axs = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    #     axs = axs.ravel()\n",
    "\n",
    "    #     for i, (name, method) in enumerate(methods.items()):\n",
    "    #         if name == \"LDA\":\n",
    "    #             X_transformed_test = method.fit_transform(X_test, y_test)\n",
    "    #         else:\n",
    "    #             X_transformed_test = method.fit_transform(X_test)\n",
    "    #         highlight_wrong_points(axs[i], X_transformed_test, y_test, eval(f\"y_pred_{model}\"), name)\n",
    "\n",
    "    #     fig.savefig(f\"{model}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('digits')  # 更改数据集名称以尝试不同的数据集\n",
    "# datasets = ['digits', 'usps']\n",
    "# for dataset in datasets:\n",
    "#     task2(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task2(dataset_name):\n",
    "    # 加载数据集\n",
    "    X, y = load_dataset(dataset_name)\n",
    "\n",
    "    # 预处理\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # 划分训练、验证、测试集\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=1 / 9, random_state=42)\n",
    "\n",
    "    # 创建半监督数据集\n",
    "    n_labeled = len(X_train) // 10\n",
    "    mask = np.zeros(len(X_train), dtype=bool)\n",
    "    mask[:n_labeled] = True\n",
    "    np.random.shuffle(mask)\n",
    "\n",
    "    # 监督线性回归（仅使用带有标签的样本）\n",
    "    X_train_labeled = X_train[mask]\n",
    "    y_train_labeled = y_train[mask]\n",
    "    n_classes = len(np.unique(y))\n",
    "    y_train_one_hot = np.eye(n_classes)[y_train_labeled]\n",
    "\n",
    "    accuracy_RLS_all = []\n",
    "    accuracy_manifold_all = []\n",
    "    for i in range(5):\n",
    "        print('Round:', i)\n",
    "        ## RLS\n",
    "        # 创建并训练模型\n",
    "        rls = RLS()\n",
    "        rls.fit(X_train_labeled, y_train_one_hot)\n",
    "\n",
    "        # 预测\n",
    "        y_pred_rls = rls.predict(X_test)\n",
    "        y_pred_rls = np.argmax(y_pred_rls, axis=1).squeeze()\n",
    "\n",
    "        # 计算准确率\n",
    "        accuracy_RLS = np.mean(y_pred_rls == y_test)\n",
    "        print(\"RLS Accuracy:\", accuracy_RLS)\n",
    "        accuracy_RLS_all.append(accuracy_RLS)\n",
    "\n",
    "        ## LapRLS\n",
    "        # 使用验证集选择最佳的gamma_I\n",
    "        best_gamma_I = 0\n",
    "        best_accuracy = 0\n",
    "        for gamma_I in np.logspace(1, 6, 6):\n",
    "            laprls = LapRLS(gamma_I=gamma_I)\n",
    "            laprls.fit(X_train[mask], X_train[~mask], y_train_one_hot)\n",
    "\n",
    "            y_pred_val = laprls.predict(X_val)\n",
    "            y_pred_val = np.argmax(y_pred_val, axis=1)\n",
    "            # fix the bug\n",
    "            y = []\n",
    "            for i in y_pred_val:\n",
    "                y.append(i.item())\n",
    "            y_pred_val = np.array(y)\n",
    "            accuracy = np.mean(y_pred_val == y_val)\n",
    "            # print(gamma_I, accuracy)\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_gamma_I = gamma_I\n",
    "\n",
    "        # 使用最佳的gamma_I重新训练模型\n",
    "        laprls = LapRLS(gamma_I=best_gamma_I)\n",
    "        laprls.fit(X_train[mask], X_train[~mask], y_train_one_hot)\n",
    "\n",
    "        # 预测\n",
    "        y_pred_laprls = laprls.predict(X_test)\n",
    "        y_pred_laprls = np.argmax(y_pred_laprls, axis=1)\n",
    "        # fix the bug\n",
    "        y = []\n",
    "        for i in y_pred_laprls:\n",
    "            y.append(i.item())\n",
    "        y_pred_laprls = np.array(y)\n",
    "\n",
    "        # 计算准确率\n",
    "        accuracy_manifold = np.mean(y_pred_laprls == y_test)\n",
    "        print(f\"LapRLS Accuracy (best gamma_I = {best_gamma_I}):\", accuracy_manifold)\n",
    "        accuracy_manifold_all.append(accuracy_manifold)\n",
    "    return accuracy_RLS_all, accuracy_manifold_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round: 0\n",
      "RLS Accuracy: 0.8111111111111111\n",
      "LapRLS Accuracy (best gamma_I = 1000.0): 0.8833333333333333\n",
      "Round: 1\n",
      "RLS Accuracy: 0.8111111111111111\n",
      "LapRLS Accuracy (best gamma_I = 1000.0): 0.8833333333333333\n",
      "Round: 2\n",
      "RLS Accuracy: 0.8111111111111111\n",
      "LapRLS Accuracy (best gamma_I = 1000.0): 0.8833333333333333\n",
      "Round: 3\n",
      "RLS Accuracy: 0.8111111111111111\n",
      "LapRLS Accuracy (best gamma_I = 1000.0): 0.8833333333333333\n",
      "Round: 4\n",
      "RLS Accuracy: 0.8111111111111111\n",
      "LapRLS Accuracy (best gamma_I = 1000.0): 0.8833333333333333\n",
      "RLS: Mean Std\n",
      "0.8111111111111111 0.0\n",
      "LapRLS: Mean Std\n",
      "0.8833333333333332 1.1102230246251565e-16\n"
     ]
    }
   ],
   "source": [
    "datasets = ['digits']#, 'usps']\n",
    "means = []\n",
    "stds = []\n",
    "for dataset in datasets:\n",
    "    accuracy_RLS, accuracy_manifold = task2(dataset)\n",
    "    print('RLS: Mean Std')\n",
    "    print(np.mean(accuracy_RLS), np.std(accuracy_RLS))\n",
    "    print('LapRLS: Mean Std')\n",
    "    print(np.mean(accuracy_manifold), np.std(accuracy_manifold))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
